#!/usr/bin/env python3
"""
Cognitive Archaeology Tribunal - Main CLI
Command-line interface for running the complete audit suite.
"""

from cognitive_tribunal.outputs.triage_report import TriageReportGenerator
from cognitive_tribunal.outputs.knowledge_graph import KnowledgeGraphGenerator
from cognitive_tribunal.outputs.inventory import InventoryGenerator
from cognitive_tribunal.modules.web_bookmark_analyzer import WebBookmarkAnalyzer
from cognitive_tribunal.modules.org_repo_analyzer import OrgRepoAnalyzer
from cognitive_tribunal.modules.personal_repo_analyzer import PersonalRepoAnalyzer
from cognitive_tribunal.modules.ai_context_aggregator import AIContextAggregator
from cognitive_tribunal.modules.archive_scanner import ArchiveScanner
import os
import sys
import argparse
from pathlib import Path
from typing import Optional

# Try to import rich for better UX, graceful fallback if missing
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.theme import Theme
    console = Console(theme=Theme({"success": "green", "danger": "bold red"}))
    HAS_RICH = True
except ImportError:
    HAS_RICH = False
    console = None

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))


def main():
    """Main entry point for the CLI."""
    parser = argparse.ArgumentParser(
        description='Cognitive Archaeology Tribunal - Comprehensive digital archaeology tool',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Run all modules
  python main.py --all --output-dir ./output
  
  # Scan archives only
  python main.py --scan-archives /path/to/archives --output-dir ./output
  
  # Analyze personal repos
  python main.py --personal-repos username --output-dir ./output
  
  # Analyze org repos
  python main.py --org-repos orgname --output-dir ./output
  
  # Load AI conversations
  python main.py --ai-conversations /path/to/chatgpt/export --output-dir ./output
        """
    )

    # Module selection
    parser.add_argument('--all', action='store_true',
                        help='Run all modules (requires other arguments)')
    parser.add_argument('--scan-archives', metavar='PATH',
                        help='Scan archive directories (comma-separated paths)')
    parser.add_argument('--ai-conversations', metavar='PATH',
                        help='Load AI conversations from path')
    parser.add_argument('--personal-repos', metavar='USERNAME',
                        help='Analyze personal GitHub repos')
    parser.add_argument('--org-repos', metavar='ORGNAME',
                        help='Analyze organization GitHub repos')
    parser.add_argument('--web-bookmarks', metavar='PATH',
                        help='Analyze web bookmarks from an export file')

    # Configuration
    parser.add_argument(
        '--github-token', help='GitHub personal access token (or use GITHUB_TOKEN env var)')
    parser.add_argument('--output-dir', default='./output',
                        help='Output directory (default: ./output)')
    parser.add_argument('--no-inventory', action='store_true',
                        help='Skip inventory generation')
    parser.add_argument('--no-graph', action='store_true',
                        help='Skip knowledge graph generation')
    parser.add_argument('--no-triage', action='store_true',
                        help='Skip triage report generation')

    args = parser.parse_args()

    # Validate arguments
    if not (args.all or args.scan_archives or args.ai_conversations or args.personal_repos or args.org_repos or args.web_bookmarks):
        if HAS_RICH and len(sys.argv) == 1:
            # Show Welcome Screen
            welcome_text = """
[bold]Cognitive Archaeology Tribunal[/bold] is a comprehensive digital archaeology tool designed to audit, organize, and preserve your scattered digital life.

[bold cyan]Available Modules:[/bold cyan]
• [green]Archive Scanner[/green]: Audit files across local and cloud drives
• [green]AI Context[/green]: Analyze ChatGPT and AI conversations
• [green]Repo Analyzer[/green]: Audit personal and organization GitHub repositories
• [green]Web Bookmarks[/green]: Parse and analyze bookmark exports

[bold cyan]Quick Start:[/bold cyan]
Run with [yellow]--help[/yellow] to see all options, or try:
  [dim]python main.py --scan-archives ./my_data[/dim]
            """
            console.print(Panel(welcome_text.strip(
            ), title="✨ Cognitive Archaeology Tribunal ✨", border_style="cyan"))
            sys.exit(0)
        else:
            parser.error('At least one module must be specified')

    if HAS_RICH:
        console.print(
            Panel("Starting Archaeological Dig...", style="bold cyan"))
    else:
        print("=" * 70)
        print("COGNITIVE ARCHAEOLOGY TRIBUNAL")
        print("Comprehensive Archaeological Dig Tool")
        print("=" * 70)
        print()

    # Helper for status updates
    from contextlib import contextmanager

    @contextmanager
    def status_msg(msg):
        if HAS_RICH:
            with console.status(f"[bold cyan]{msg}...", spinner="dots"):
                yield
        else:
            print(f"{msg}...")
            yield

    def print_success(msg):
        if HAS_RICH:
            console.print(f"[success]✓[/success] {msg}")
        else:
            print(f"✓ {msg}")

    def print_error(msg):
        if HAS_RICH:
            console.print(f"[danger]✗ {msg}[/danger]")
        else:
            print(f"✗ {msg}")

    # Create output directory
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Initialize results storage
    results = {}

    # Module 1: Archive Scanner
    if args.scan_archives:
        with status_msg("Running Archive Scanner"):
            scanner = ArchiveScanner()
            paths = [p.strip() for p in args.scan_archives.split(',')]

            if len(paths) == 1:
                archive_results = scanner.scan_directory(paths[0])
            else:
                archive_results = scanner.scan_multiple_locations(paths)

            results['archives'] = archive_results

            # Save module results
            import json
            with open(output_dir / 'archives.json', 'w') as f:
                json.dump(archive_results, f, indent=2)

        print_success(
            f"Archive scan complete. Found {archive_results.get('stats', {}).get('total_files', 0)} files")

    # Module 2: AI Context Aggregator
    if args.ai_conversations:
        with status_msg("Running AI Context Aggregator"):
            aggregator = AIContextAggregator()
            ai_results = aggregator.load_chatgpt_export(args.ai_conversations)
            results['ai_conversations'] = aggregator.get_results()

            # Save module results
            import json
            with open(output_dir / 'ai_conversations.json', 'w') as f:
                json.dump(results['ai_conversations'], f, indent=2)

        print_success(
            f"AI context aggregation complete. Loaded {ai_results.get('loaded_count', 0)} conversations")

    # Module 3: Personal Repo Analyzer
    if args.personal_repos:
        with status_msg("Running Personal Repo Analyzer"):
            try:
                analyzer = PersonalRepoAnalyzer(args.github_token)
                repo_results = analyzer.analyze_user_repos(args.personal_repos)
                results['personal_repos'] = repo_results

                # Save module results
                import json
                with open(output_dir / 'personal_repos.json', 'w') as f:
                    json.dump(repo_results, f, indent=2)

                print_success(
                    f"Personal repo analysis complete. Analyzed {repo_results.get('stats', {}).get('total_repos', 0)} repositories")
            except Exception as e:
                print_error(f"Error analyzing personal repos: {e}")

    # Module 4: Org Repo Analyzer
    if args.org_repos:
        with status_msg("Running Org Repo Analyzer"):
            try:
                analyzer = OrgRepoAnalyzer(args.github_token)
                org_results = analyzer.analyze_org_repos(args.org_repos)
                results['org_repos'] = org_results

                # Save module results
                import json
                with open(output_dir / 'org_repos.json', 'w') as f:
                    json.dump(org_results, f, indent=2)

                print_success(
                    f"Org repo analysis complete. Analyzed {org_results.get('stats', {}).get('total_repos', 0)} repositories")
            except Exception as e:
                print_error(f"Error analyzing org repos: {e}")

    # Module 5: Web Bookmark Analyzer
    if args.web_bookmarks:
        with status_msg("Running Web Bookmark Analyzer"):
            analyzer = WebBookmarkAnalyzer()
            bookmark_results = analyzer.analyze_bookmarks(args.web_bookmarks)
            results['web_bookmarks'] = bookmark_results

            # Save module results
            import json
            with open(output_dir / 'web_bookmarks.json', 'w') as f:
                json.dump(bookmark_results, f, indent=2)

        print_success(
            f"Web bookmark analysis complete. Found {bookmark_results.get('stats', {}).get('total_bookmarks', 0)} bookmarks")

    # Generate unified outputs
    if HAS_RICH:
        console.print(Panel("Generating Outputs", style="bold cyan"))
    else:
        print("\n" + "=" * 70)
        print("GENERATING OUTPUTS")
        print("=" * 70)

    # Unified Inventory
    if not args.no_inventory:
        with status_msg("Generating unified inventory"):
            inventory = InventoryGenerator()

            if 'archives' in results:
                inventory.add_archive_results(results['archives'])
            if 'ai_conversations' in results:
                inventory.add_ai_context_results(results['ai_conversations'])
            if 'personal_repos' in results:
                inventory.add_personal_repo_results(results['personal_repos'])
            if 'org_repos' in results:
                inventory.add_org_repo_results(results['org_repos'])
            if 'web_bookmarks' in results:
                pass

            inventory.save_to_file(str(output_dir / 'inventory.json'))
        print_success("Inventory saved")

    # Knowledge Graph
    if not args.no_graph:
        with status_msg("Generating knowledge graph"):
            graph = KnowledgeGraphGenerator()

            if not args.no_inventory:
                graph.build_from_inventory(inventory.get_inventory())
                graph.save_to_file(str(output_dir / 'knowledge_graph.json'))
                graph.export_to_cytoscape(
                    str(output_dir / 'knowledge_graph_cytoscape.json'))
        print_success("Knowledge graph saved")

    # Triage Report
    if not args.no_triage:
        with status_msg("Generating triage report"):
            triage = TriageReportGenerator()

            if 'archives' in results:
                triage.add_archive_triage(results['archives'])
            if 'ai_conversations' in results:
                triage.add_ai_context_triage(results['ai_conversations'])
            if 'personal_repos' in results:
                triage.add_personal_repo_triage(results['personal_repos'])
            if 'org_repos' in results:
                triage.add_org_repo_triage(results['org_repos'])
            if 'web_bookmarks' in results:
                pass

            triage.save_to_file(str(output_dir / 'triage_report.json'))

            # Also save as text
            with open(output_dir / 'triage_report.txt', 'w') as f:
                f.write(triage.generate_text_report())

        print_success("Triage report saved")

    # Final summary
    if HAS_RICH:
        console.print(Panel("COMPLETE!", style="bold green"))
        console.print(
            f"\nAll outputs saved to: [underline]{output_dir.absolute()}[/underline]")
        console.print("\n[bold]Generated files:[/bold]")
        for file in sorted(output_dir.glob('*')):
            console.print(f"  - {file.name}")
    else:
        print("\n" + "=" * 70)
        print("COMPLETE!")
        print("=" * 70)
        print(f"\nAll outputs saved to: {output_dir.absolute()}")
        print("\nGenerated files:")
        for file in sorted(output_dir.glob('*')):
            print(f"  - {file.name}")
    print()


if __name__ == '__main__':
    main()
